{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1668bc01",
   "metadata": {},
   "source": [
    "# Create a generative adversarial network, building and training a GAN that can generate hand-written images of digits(0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e4a78a",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "1. Build the generator and discriminator components of a GAN from scratch.\n",
    "2. Create generator and discriminator loss functions.\n",
    "3. Train your GAN and visualize the generated images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec383f6",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "Import useful packages and the dataset you will use to build and train your GAN. A visualizer function is there to investigate the images the GAN will create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c34ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in a uniform grid.\n",
    "    '''\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902d405",
   "metadata": {},
   "source": [
    "### Generator\n",
    "Create a function to make a single layer/block for the generator's neural network.Each block should include\n",
    "a linear transformation to map to another shape, a batch normalization for stabilization \n",
    "and finally a non-linear activation function (ReLU) so the output can be transformed in complex ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7da45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator block function\n",
    "def get_generator_block(input_dim, output_dim):\n",
    "    '''\n",
    "    Function for returning a block of the generator's neural network given input and output dimensions.\n",
    "    Parameters:\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        output_dim: the dimension of the output vector, a scalar\n",
    "    Returns:\n",
    "        a generator neural network layer, with a linear transformation\n",
    "        followed by a batch normalization and then a relu activation\n",
    "    '''\n",
    "    return nn.Sequential(\n",
    "        # Hint: Replace all of the \"None\" with the appropriate dimensions.\n",
    "        # The documentation may be useful if you're less familiar with PyTorch:\n",
    "        # https://pytorch.org/docs/stable/nn.html.\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "773f1279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Verify the generator block function\n",
    "def test_gen_block(in_features, out_features, num_test=1000):\n",
    "    block = get_generator_block(in_features, out_features)\n",
    "    \n",
    "    # Check the three parts\n",
    "    assert len(block) == 3\n",
    "    assert type(block[0]) == nn.Linear\n",
    "    assert type(block[1]) == nn.BatchNorm1d\n",
    "    assert type(block[2]) == nn.ReLU\n",
    "    \n",
    "    # Check the output shape\n",
    "    test_input = torch.randn(num_test, in_features)\n",
    "    test_output = block(test_input)\n",
    "    assert tuple(test_output.shape) == (num_test, out_features)\n",
    "    assert test_output.std() > 0.55\n",
    "    assert test_output.std() < 0.65\n",
    "    \n",
    "test_gen_block(25, 12)\n",
    "test_gen_block(15, 28)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ec7bc",
   "metadata": {},
   "source": [
    "###### Now a generator class can be built. It will take 3 values:\n",
    "    1. The noise vector dimension\n",
    "    2. The image dimension\n",
    "    3. The initial hidden dimension\n",
    "\n",
    "Using these values, the generator will build a nn with 5 layers/blocks. Beginning with the noise vector ,the \n",
    "generator will apply non-linear transformations via the block function until the tensor is mapped to the size of\n",
    "the image to be outputted(the same size as the real images from MNIST). The final layer needs doesnot need a \n",
    "normalization or activation function, but foes need to be scaled with a sigmoid function.\n",
    "\n",
    "Finally a forward pass function is available that takes in a noise vector and generates an image of the output \n",
    "dimension using the nn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b89b9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Generator Class\n",
    "    Values:\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        im_dim: the dimension of the images, fitted for the dataset used, a scalar\n",
    "            (MNIST images are 28 x 28 so that is your default)\n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):\n",
    "        super(Generator, self).__init__()\n",
    "        # Build the neural network\n",
    "        self.gen = nn.Sequential(\n",
    "            get_generator_block(z_dim, hidden_dim),\n",
    "            get_generator_block(hidden_dim, hidden_dim * 2),\n",
    "            get_generator_block(hidden_dim * 2, hidden_dim * 4),\n",
    "            get_generator_block(hidden_dim * 4, hidden_dim * 8),\n",
    "            nn.Linear(hidden_dim*8, im_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        '''\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor, returns generated images.\n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
    "        '''\n",
    "        return self.gen(noise)\n",
    "    \n",
    "    # Needed for grading\n",
    "    def get_gen(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            the sequential model\n",
    "        '''\n",
    "        return self.gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cd89fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Verify the generator class\n",
    "\n",
    "def test_generator(z_dim, im_dim, hidden_dim, num_test=10000):\n",
    "    gen = Generator(z_dim, im_dim, hidden_dim).get_gen()\n",
    "    \n",
    "    # Check there are six modules in the sequential part\n",
    "    assert len(gen) == 6\n",
    "   \n",
    "    test_input = torch.randn(num_test, z_dim)\n",
    "    test_output = gen(test_input)\n",
    "    \n",
    "    # Check that the output shape is correct\n",
    "    assert tuple(test_output.shape) == (num_test, im_dim)\n",
    "    assert test_output.max() < 1, \"Make sure to use a sigmoid\"\n",
    "    assert test_output.min() > 0, \"Make sure to use a sigmoid\"\n",
    "    assert test_output.min() < 0.5, \"Don't use a block in your solution\"\n",
    "    assert test_output.std() > 0.05, \"Don't use batchnorm here\"\n",
    "    assert test_output.std() < 0.15, \"Don't use batchnorm here\"\n",
    "    \n",
    "test_generator(5, 10, 20)\n",
    "test_generator(20, 8, 24)\n",
    "print(\"Success!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c830e",
   "metadata": {},
   "source": [
    "#### Noise\n",
    "Create noise vector to be able to use the generator, as the noise vector z has the important role of making sure \n",
    "the images generated from the same class don't all look the same--think of it as a random seed. It is generated \n",
    "randomly using PyTorch by sampling random numbers from the normal distribution. Since multiple images will be \n",
    "processed per pass, all the noise vectors will be generated at once.\n",
    "Note: Whenever a new tensor is created using torch.ones, torch.zeros, or torch.randn, it is either created on a \n",
    "    target device, e.g. torch.ones(3, 3, device=device), or move into the target device using torch.ones(3,3).to(device).\n",
    "    In general, torch.ones_like and torch.zeros_like is used instead of torch.ones or torch.zeros where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cfdee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    '''\n",
    "    Function for creating noise vectors: Given the dimensions (n_samples, z_dim),\n",
    "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
    "    Parameters:\n",
    "        n_samples: the number of samples to generate, a scalar\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        device: the device type\n",
    "    '''\n",
    "    # NOTE: To use this on GPU with device='cuda', make sure to pass the device\n",
    "    # argument tot the function you use to generate the noise\n",
    "    #### START CODE HERE ####\n",
    "    noise = torch.randn(n_samples, z_dim, device=device)\n",
    "    return noise\n",
    "    #### END CODE HERE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a33882e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Verify the noise vector function\n",
    "def test_get_noise(n_samples, z_dim, device='cpu'):\n",
    "    noise = get_noise(n_samples, z_dim, device)\n",
    "    \n",
    "    # Make sure a normal distribution was used\n",
    "    assert tuple(noise.shape) == (n_samples, z_dim)\n",
    "    assert torch.abs(noise.std() - torch.tensor(1.0)) < 0.01\n",
    "    assert str(noise.device).startswith(device)\n",
    "    \n",
    "test_get_noise(1000, 100, 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    test_get_noise(1000, 32, 'cuda')\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0201b8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
